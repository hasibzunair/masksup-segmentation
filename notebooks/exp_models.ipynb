{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental notebook for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "#sys.path.insert(0,\"..\")\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cv2 \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(0)\n",
    "os.environ['PYTHONHASHSEED'] = str(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Device\n",
    "DEVICE = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# EXPERIMENT_NAME = \"coin_unet_isic2018\"\n",
    "\n",
    "# ROOT_DIR = os.path.abspath(\".\")\n",
    "# LOG_PATH = os.path.join(ROOT_DIR, \"logs\", EXPERIMENT_NAME)\n",
    "\n",
    "# if not os.path.exists(os.path.join(ROOT_DIR, \"logs\")):\n",
    "#     os.mkdir(os.path.join(ROOT_DIR, \"logs\"))\n",
    "    \n",
    "# if not os.path.exists(LOG_PATH):\n",
    "#     os.mkdir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import build_unet\n",
    "from models.LeViTUNet128s import Build_LeViT_UNet_128s\n",
    "from models.LeViTUNet192 import Build_LeViT_UNet_192\n",
    "from models.LeViTUNet384 import Build_LeViT_UNet_384\n",
    "from models.unetplusplus import NestedUNet\n",
    "from models.resnet import rf_lw50, rf_lw101, rf_lw152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from segformer_pytorch import Segformer\n",
    "\n",
    "model = Segformer(\n",
    "    dims = (32, 64, 160, 256),      # dimensions of each stage\n",
    "    heads = (1, 2, 5, 8),           # heads of each stage\n",
    "    ff_expansion = (8, 8, 4, 4),    # feedforward expansion factor of each stage\n",
    "    reduction_ratio = (8, 4, 2, 1), # reduction ratio of each stage for efficient attention\n",
    "    num_layers = 2,                 # num layers of each stage\n",
    "    decoder_dim = 256,              # decoder dimension\n",
    "    num_classes = 40                 # number of segmentation classes\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224)\n",
    "pred = model(x) # (1, 4, 64, 64)  # output is (H/4, W/4) map of the number of segmentation classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf_lw152(40, imagenet=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(torch.randn(1, 3, 224, 224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randn(1, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (\n",
    "    cv2.resize(\n",
    "        output[0, :40].data.cpu().numpy().transpose(1, 2, 0),\n",
    "        target.size()[1:][::-1],\n",
    "        interpolation=cv2.INTER_CUBIC,\n",
    "    )\n",
    "    .argmax(axis=2)\n",
    "    .astype(np.uint8)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.interpolate(output, size=(224, 224), mode=\"bilinear\", align_corners=True)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeViT_128S 304340946 FLOPs 15894627 parameters\n",
    "# the number of parameters: 15894627 ==> 15.89 M\n",
    "# Computational complexity:       17.42 GMac\n",
    "# Number of parameters:           15.89 M \n",
    "\n",
    "# LeViT_192 656833916 FLOPs 19894150 parameters\n",
    "# the number of parameters: 19894150 ==> 19.89 M\n",
    "\n",
    "# Computational complexity:       25.4 GMac\n",
    "# Number of parameters:           52.15 M \n",
    "# LeViT_384 2351399380 FLOPs 52154213 parameters\n",
    "# the number of parameters: 52154213 ==> 52.15 M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NestedUNet()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "output = model(torch.randn(1, 3, 224, 224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ODOC_seg_edge()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "output = model(torch.randn(1, 3, 256, 256))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Build_LeViT_UNet_128s(num_classes=1, pretrained=True)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "output = model(torch.randn(1, 3, 224, 224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From train script\n",
    "\n",
    "# 128s\n",
    "# All parameters  15894627\n",
    "# Trainable parameters  15894627\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
