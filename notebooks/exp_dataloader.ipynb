{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental notebook for different data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "#sys.path.insert(0,\"..\")\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(0)\n",
    "os.environ['PYTHONHASHSEED'] = str(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# EXPERIMENT_NAME = \"unet_isic2018\"\n",
    "\n",
    "# ROOT_DIR = os.path.abspath(\".\")\n",
    "# LOG_PATH = os.path.join(ROOT_DIR, \"logs\", EXPERIMENT_NAME)\n",
    "\n",
    "# if not os.path.exists(os.path.join(ROOT_DIR, \"logs\")):\n",
    "#     os.mkdir(os.path.join(ROOT_DIR, \"logs\"))\n",
    "    \n",
    "# if not os.path.exists(LOG_PATH):\n",
    "#     os.mkdir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = np.load('datasets/NYUDV2/cmap.npy')\n",
    "cmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYUDV2_dataloader(Dataset):\n",
    "    \"\"\"\n",
    "    NYUDV2 data loader with Irregular Masks Dataset (https://arxiv.org/abs/1804.07723)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_folder, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self._data_folder = data_folder\n",
    "        self.build_dataset()\n",
    "\n",
    "    def build_dataset(self):\n",
    "        if self.is_train:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"train_images\")\n",
    "            self._label_folder = os.path.join(self._data_folder, \"train_labels\")\n",
    "            self.train_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.train_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        else:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"val_images\")\n",
    "            self._label_folder = os.path.join(self._data_folder, \"val_labels\")\n",
    "            self.test_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.test_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        \n",
    "        self._scribbles_folder = os.path.join(self._data_folder, 'SCRIBBLES')\n",
    "        self._scribbles = sorted(glob.glob(self._scribbles_folder + \"/*.png\"))[::-1][:1000] # For heavy masking [::-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.is_train:\n",
    "            img_path = self.train_images[idx]\n",
    "            mask_path = self.train_labels[idx]\n",
    "            scribble_path = self._scribbles[random.randint(0,950)] # pick randomly from first 1000 scribbles\n",
    "        else:\n",
    "            img_path = self.test_images[idx]\n",
    "            mask_path = self.test_labels[idx]\n",
    "            scribble_path = self._scribbles[idx]\n",
    "        \n",
    "        # Read image, mask and scribble\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = np.array(Image.open(mask_path))\n",
    "        mask = cv2.resize(mask, (224, 224), interpolation = cv2.INTER_NEAREST)\n",
    "        scribble = Image.open(scribble_path).convert('P')\n",
    "\n",
    "        transforms_image = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                       transforms.CenterCrop((224,224)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "        transforms_mask = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                              transforms.CenterCrop((224,224)),\n",
    "                                              transforms.ToTensor()])\n",
    "        # Convert to torch tensors\n",
    "        image = transforms_image(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        scribble = transforms_mask(scribble)\n",
    "\n",
    "        # Masked image\n",
    "        partial_image1 = image * (torch.max(scribble) - scribble) \n",
    "        partial_image2 = image * scribble\n",
    "        sample = {'image': image, \n",
    "                  'mask': mask, \n",
    "                  'partial_image1': partial_image1,\n",
    "                  'partial_image2': partial_image2}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NYUDV2_dataloader(\"datasets/NYUDV2\")\n",
    "test_dataset = NYUDV2_dataloader(\"datasets/NYUDV2\", is_train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True, num_workers=8) # 8\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = next(iter(train_dataloader))\n",
    "x = dt[\"image\"]\n",
    "y = dt[\"mask\"]\n",
    "z = dt[\"partial_image1\"]\n",
    "x.shape, y.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(ten):\n",
    "    ten =(ten[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "    ten=(ten*255).astype(np.uint8)\n",
    "    return ten\n",
    "\n",
    "a = to_img(x)\n",
    "print(a.shape)\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = y[0].data.cpu().numpy()\n",
    "yy[yy==255] = 0\n",
    "mask = cmap[yy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(yy), np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite('example.png', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISIC2018_dataloader(Dataset):\n",
    "    \"\"\"\n",
    "    ISIC 2018 data loader with Irregular Masks Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_folder, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self._data_folder = data_folder\n",
    "        self.build_dataset()\n",
    "\n",
    "    def build_dataset(self):\n",
    "        self._input_folder = os.path.join(self._data_folder, 'ISIC2018_Task1-2_Training_Input')\n",
    "        self._label_folder = os.path.join(self._data_folder, 'ISIC2018_Task1_Training_GroundTruth')\n",
    "        self._scribbles_folder = os.path.join(self._data_folder, 'SCRIBBLES')\n",
    "        self._images = sorted(glob.glob(self._input_folder + \"/*.jpg\"))\n",
    "        self._labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        self._scribbles = sorted(glob.glob(self._scribbles_folder + \"/*.png\")) # For heavy masking [::-1]\n",
    "        \n",
    "        self.train_images, self.test_images, self.train_labels, self.test_labels = train_test_split(self._images, \n",
    "                                                                                                    self._labels,\n",
    "                                                                                                    test_size=0.2, shuffle=False, random_state=0)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.is_train:\n",
    "            img_path = self.train_images[idx]\n",
    "            mask_path = self.train_labels[idx]\n",
    "            scribble_path = self._scribbles[np.random.randint(1000)] # pick randomly from first 1000 scribbles\n",
    "        else:\n",
    "            img_path = self.test_images[idx]\n",
    "            mask_path = self.test_labels[idx]\n",
    "            scribble_path = self._scribbles[idx]\n",
    "            \n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        \n",
    "        mask[mask<=127] = 0\n",
    "        mask[mask>127] = 1\n",
    "        mask = cv2.resize(mask, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        scribble = Image.open(scribble_path).convert('P')\n",
    "        \n",
    "        \n",
    "        transforms_image = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "        \n",
    "        transforms_mask = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor()])\n",
    "        \n",
    "        image = transforms_image(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        scribble = transforms_mask(scribble)\n",
    "        \n",
    "        ###############################\n",
    "        #partial_image1 = image * mask * cmask\n",
    "        #partial_image2 = image * cmask * (1 - mask)\n",
    "        ###############################\n",
    "        \n",
    "        # Masked image\n",
    "        partial_image1 = image * (torch.max(scribble) - scribble) \n",
    "        partial_image2 = image * scribble\n",
    "        \n",
    "        sample = {'image': image, \n",
    "                  'mask': mask, \n",
    "                  'partial_image1': partial_image1,\n",
    "                  'partial_image2': partial_image2}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class GLAS_dataloader(Dataset):\n",
    "    def __init__(self, data_folder, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self._data_folder = data_folder\n",
    "        self.build_dataset()\n",
    "\n",
    "    def build_dataset(self):\n",
    "        if self.is_train:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"train\", 'img')\n",
    "            self._label_folder = os.path.join(self._data_folder, \"train\", 'labelcol')\n",
    "            self.train_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.train_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        else:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"test\", 'img')\n",
    "            self._label_folder = os.path.join(self._data_folder, \"test\", 'labelcol')\n",
    "            self.test_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.test_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        \n",
    "        self._scribbles_folder = os.path.join(self._data_folder, 'SCRIBBLES')\n",
    "        self._scribbles = sorted(glob.glob(self._scribbles_folder + \"/*.png\"))[:1000] # For heavy masking [::-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.is_train:\n",
    "            img_path = self.train_images[idx]\n",
    "            mask_path = self.train_labels[idx]\n",
    "            scribble_path = self._scribbles[random.randint(0,999)] # pick randomly from first 1000 scribbles\n",
    "        else:\n",
    "            img_path = self.test_images[idx]\n",
    "            mask_path = self.test_labels[idx]\n",
    "            scribble_path = self._scribbles[idx]\n",
    "            \n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask[mask<=127] = 0\n",
    "        mask[mask>127] = 1\n",
    "        mask = cv2.resize(mask, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        scribble = Image.open(scribble_path).convert('P')\n",
    "        \n",
    "        \n",
    "        transforms_image = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "        \n",
    "        transforms_mask = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor()])\n",
    "        \n",
    "        image = transforms_image(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        scribble = transforms_mask(scribble)\n",
    "        \n",
    "        ###############################\n",
    "        #partial_image1 = image * mask * cmask\n",
    "        #partial_image2 = image * cmask * (1 - mask)\n",
    "        ###############################\n",
    "        \n",
    "        # Masked image\n",
    "        partial_image1 = image * (torch.max(scribble) - scribble) \n",
    "        partial_image2 = image * scribble\n",
    "        \n",
    "        sample = {'image': image, \n",
    "                  'mask': mask, \n",
    "                  'partial_image1': partial_image1,\n",
    "                  'partial_image2': partial_image2}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class RITE_dataloader(Dataset):\n",
    "    def __init__(self, data_folder, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self._data_folder = data_folder\n",
    "        self.build_dataset()\n",
    "\n",
    "    def build_dataset(self):\n",
    "        if self.is_train:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"train\", 'img')\n",
    "            self._label_folder = os.path.join(self._data_folder, \"train\", 'labelcol')\n",
    "            self.train_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.train_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        else:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"test\", 'img')\n",
    "            self._label_folder = os.path.join(self._data_folder, \"test\", 'labelcol')\n",
    "            self.test_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.test_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        \n",
    "        self._scribbles_folder = os.path.join(self._data_folder, 'SCRIBBLES')\n",
    "        self._scribbles = sorted(glob.glob(self._scribbles_folder + \"/*.png\"))[:1000] # For heavy masking [::-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.is_train:\n",
    "            img_path = self.train_images[idx]\n",
    "            mask_path = self.train_labels[idx]\n",
    "            scribble_path = self._scribbles[random.randint(0,950)] # pick randomly from first 1000 scribbles\n",
    "        else:\n",
    "            img_path = self.test_images[idx]\n",
    "            mask_path = self.test_labels[idx]\n",
    "            scribble_path = self._scribbles[idx]\n",
    "            \n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask[mask<=127] = 0\n",
    "        mask[mask>127] = 1\n",
    "        mask = cv2.resize(mask, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        scribble = Image.open(scribble_path).convert('P')\n",
    "        \n",
    "        \n",
    "        transforms_image = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "        \n",
    "        transforms_mask = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor()])\n",
    "        \n",
    "        image = transforms_image(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        scribble = transforms_mask(scribble)\n",
    "        \n",
    "        ###############################\n",
    "        #partial_image1 = image * mask * cmask\n",
    "        #partial_image2 = image * cmask * (1 - mask)\n",
    "        ###############################\n",
    "        \n",
    "        # Masked image\n",
    "        partial_image1 = image * (torch.max(scribble) - scribble) \n",
    "        partial_image2 = image * scribble\n",
    "        \n",
    "        sample = {'image': image, \n",
    "                  'mask': mask, \n",
    "                  'partial_image1': partial_image1,\n",
    "                  'partial_image2': partial_image2}\n",
    "        return sample\n",
    "\n",
    "    \n",
    "class CVCLINICDB_dataloader(Dataset):\n",
    "    def __init__(self, data_folder, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self._data_folder = data_folder\n",
    "        self.build_dataset()\n",
    "\n",
    "    def build_dataset(self):\n",
    "        self._input_folder = os.path.join(self._data_folder, 'Original')\n",
    "        self._label_folder = os.path.join(self._data_folder, 'GroundTruth')\n",
    "        self._scribbles_folder = os.path.join(self._data_folder, 'SCRIBBLES')\n",
    "        self._images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "        self._labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        self._scribbles = sorted(glob.glob(self._scribbles_folder + \"/*.png\"))\n",
    "        \n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        \n",
    "        self.train_images, self.test_images, self.train_labels, self.test_labels, self.train_scribbles, self.test_scribbles = train_test_split(self._images, \n",
    "                                                                                                    self._labels,\n",
    "                                                                                                    self._scribbles[:len(self._images)],\n",
    "                                                                                                    test_size=0.1, shuffle=False, random_state=0)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.is_train:\n",
    "            img_path = self.train_images[idx]\n",
    "            mask_path = self.train_labels[idx]\n",
    "            scribble_path = self._scribbles[np.random.randint(1000)] # pick randomly from first 1000 scribbles\n",
    "        else:\n",
    "            img_path = self.test_images[idx]\n",
    "            mask_path = self.test_labels[idx]\n",
    "            scribble_path = self._scribbles[idx]\n",
    "            \n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        \n",
    "        mask[mask<=127] = 0\n",
    "        mask[mask>127] = 1\n",
    "        mask = cv2.resize(mask, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        scribble = Image.open(scribble_path).convert('P')\n",
    "        \n",
    "        \n",
    "        transforms_image = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "        \n",
    "        transforms_mask = transforms.Compose([transforms.Resize((224, 224)), transforms.CenterCrop((224,224)),\n",
    "                                             transforms.ToTensor()])\n",
    "        \n",
    "        image = transforms_image(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        scribble = transforms_mask(scribble)\n",
    "        \n",
    "        ###############################\n",
    "        #partial_image1 = image * mask * cmask\n",
    "        #partial_image2 = image * cmask * (1 - mask)\n",
    "        ###############################\n",
    "        \n",
    "        # Masked image\n",
    "        partial_image1 = image * (torch.max(scribble) - scribble) \n",
    "        partial_image2 = image * scribble\n",
    "        \n",
    "        sample = {'image': image, \n",
    "                  'mask': mask, \n",
    "                  'partial_image1': partial_image1,\n",
    "                  'partial_image2': partial_image2}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class POLYPS_dataloader(Dataset):\n",
    "    \"\"\"\n",
    "    GLAS data loader with Irregular Masks Dataset (https://arxiv.org/abs/1804.07723)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_folder, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self._data_folder = data_folder\n",
    "        self.build_dataset()\n",
    "\n",
    "    def build_dataset(self):\n",
    "        if self.is_train:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"TrainDataset\", 'image')\n",
    "            self._label_folder = os.path.join(self._data_folder, \"TrainDataset\", 'mask')\n",
    "            self.train_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.train_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        else:\n",
    "            self._input_folder = os.path.join(self._data_folder, \"TestDataset\", \"CVC-ClinicDB\", 'images')\n",
    "            self._label_folder = os.path.join(self._data_folder, \"TestDataset\", \"CVC-ClinicDB\", 'masks')\n",
    "            self.test_images = sorted(glob.glob(self._input_folder + \"/*.png\"))\n",
    "            self.test_labels = sorted(glob.glob(self._label_folder + \"/*.png\"))\n",
    "        \n",
    "        self._scribbles_folder = os.path.join(self._data_folder, \"TrainDataset\", 'SCRIBBLES')\n",
    "        self._scribbles = sorted(glob.glob(self._scribbles_folder + \"/*.png\"))[:1000] # For heavy masking [::-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.is_train:\n",
    "            img_path = self.train_images[idx]\n",
    "            mask_path = self.train_labels[idx]\n",
    "            scribble_path = self._scribbles[random.randint(0,950)] # pick randomly from first 1000 scribbles\n",
    "        else:\n",
    "            img_path = self.test_images[idx]\n",
    "            mask_path = self.test_labels[idx]\n",
    "            scribble_path = self._scribbles[idx]\n",
    "            \n",
    "        # Read image, mask and scribble\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask[mask<=127] = 0\n",
    "        mask[mask>127] = 1\n",
    "        mask = cv2.resize(mask, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        scribble = Image.open(scribble_path).convert('P')\n",
    "        \n",
    "        transforms_image = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                               transforms.CenterCrop((224,224)),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "        transforms_mask = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                              transforms.CenterCrop((224,224)),\n",
    "                                              transforms.ToTensor()])\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = transforms_image(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        scribble = transforms_mask(scribble)\n",
    "\n",
    "        # Masked image\n",
    "        partial_image1 = image * (torch.max(scribble) - scribble) \n",
    "        partial_image2 = image * scribble\n",
    "        \n",
    "        sample = {'image': image, \n",
    "                  'mask': mask, \n",
    "                  'partial_image1': partial_image1,\n",
    "                  'partial_image2': partial_image2}\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "train_dataset = POLYPS_dataloader(\"datasets/POLYPS\")\n",
    "test_dataset = POLYPS_dataloader(\"datasets/POLYPS\", is_train=False)\n",
    "\n",
    "# train_dataset = GLAS_dataloader(\"datasets/GLAS\")\n",
    "# test_dataset = GLAS_dataloader(\"datasets/GLAS\", is_train=False)\n",
    "\n",
    "# train_dataset = RITE_dataloader(\"datasets/RITE\")\n",
    "# test_dataset = RITE_dataloader(\"datasets/RITE\", is_train=False)\n",
    "\n",
    "# train_dataset = CVCLINICDB_dataloader(\"datasets/CVCLINICDB\")\n",
    "# test_dataset = CVCLINICDB_dataloader(\"datasets/CVCLINICDB\", is_train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = next(iter(train_dataloader))\n",
    "x = dt[\"image\"]\n",
    "y = dt[\"mask\"]\n",
    "z = dt[\"partial_image1\"]\n",
    "x.shape, y.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(y) # tensor([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(ten):\n",
    "    ten =(ten[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "    ten=(ten*255).astype(np.uint8)\n",
    "    return ten\n",
    "\n",
    "a = to_img(x)\n",
    "print(a.shape)\n",
    "plt.imshow(a)\n",
    "#plt.imshow(a, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
    "#         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
    "#         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
    "#         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
    "#         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  65,\n",
    "#         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
    "#         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
    "#         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
    "#        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
    "#        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
    "#        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
    "#        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
    "#        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
    "#        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
    "#        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
    "#        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
    "#        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
    "#        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
    "#        235, 236, 237, 238, 239], dtype=uint8)\n",
    "\n",
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = to_img(y)\n",
    "print(a.shape)\n",
    "plt.imshow(a, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(a) # array([127, 255], dtype=uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = to_img(z)\n",
    "print(a.shape)\n",
    "plt.imshow(a, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
