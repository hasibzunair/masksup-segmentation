{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train segmentation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "#sys.path.insert(0,\"..\")\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(0)\n",
    "os.environ['PYTHONHASHSEED'] = str(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "EXPERIMENT_NAME = \"unet_isic2018\"\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "LOG_PATH = os.path.join(ROOT_DIR, \"logs\", EXPERIMENT_NAME)\n",
    "\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    os.mkdir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import ISIC2018_dataloader\n",
    "\n",
    "train_dataset = ISIC2018_dataloader(\"datasets/ISIC2018\")\n",
    "test_dataset = ISIC2018_dataloader(\"datasets/ISIC2018\", is_train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = next(iter(train_dataloader))\n",
    "# x = dt[\"image\"]\n",
    "# y = dt[\"mask\"]\n",
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_img(ten):\n",
    "#     ten =(ten[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "#     ten=(ten*255).astype(np.uint8)\n",
    "#     return ten\n",
    "\n",
    "# a = to_img(x)\n",
    "# print(a.shape)\n",
    "# plt.imshow(a)\n",
    "# #plt.imshow(a, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from models import build_unet\n",
    "\n",
    "# Define model\n",
    "#model = build_resnet50_unet()\n",
    "#model = ODOC_seg_edge()\n",
    "model = build_unet()\n",
    "\n",
    "# Send to GPU and initialize weights\n",
    "model = model.to(DEVICE)\n",
    "#model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters  31043521\n",
      "Trainable parameters  31043521\n"
     ]
    }
   ],
   "source": [
    "# All parameters\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"All parameters \", all_params)\n",
    "\n",
    "# Trainable parameters\n",
    "all_train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Trainable parameters \", all_train_params)\n",
    "\n",
    "# Unet 31043521"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup optim and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss() # loss combines a Sigmoid layer and the BCELoss in one single class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        data, target = data[\"image\"].to(DEVICE), data[\"mask\"].to(DEVICE)\n",
    "        output = model.forward(data.float())\n",
    "        loss = criterion(output.float(), target.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % 10 == 0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
    "        #         100. * batch_idx / len(train_dataloader), loss.data))\n",
    "            \n",
    "def test(model):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        jaccard = 0\n",
    "        dice = 0\n",
    "\n",
    "        for data in test_dataloader:\n",
    "            data, target = data[\"image\"].to(DEVICE), data[\"mask\"].to(DEVICE)\n",
    "            output = model(data.float())  \n",
    "            test_loss += criterion(output.float(), target.float()).item()\n",
    "            \n",
    "            output = torch.sigmoid(output) # Turn activations into probabilities by feeding through sigmoid\n",
    "            gt = target.permute(0, 2, 3, 1).squeeze().detach().cpu().numpy()\n",
    "            pred = output.permute(0, 2, 3, 1).squeeze().detach().cpu().numpy() > 0.5\n",
    "\n",
    "            intersection = pred * gt\n",
    "            union = pred + gt - intersection\n",
    "            jaccard += (np.sum(intersection)/np.sum(union))  \n",
    "            dice += (2. * np.sum(intersection) ) / (np.sum(pred) + np.sum(gt))\n",
    "    \n",
    "        test_loss /= len(test_dataloader)\n",
    "        jaccard /= len(test_dataloader)\n",
    "        dice /= len(test_dataloader)\n",
    "\n",
    "        losses.append(test_loss)\n",
    "        jacs.append(jaccard)\n",
    "        dices.append(dice)\n",
    "\n",
    "\n",
    "        print('Average Loss: {:.3f}'.format(test_loss))\n",
    "        print('Jaccard Index : {:.3f}'.format(jaccard * 100))\n",
    "        print('Dice Coefficient : {:.3f}'.format(dice * 100))\n",
    "        print('==========================================')\n",
    "        print('==========================================')\n",
    "        return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Average Loss: 0.318\n",
      "Jaccard Index : 66.045\n",
      "Dice Coefficient : 75.480\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.755\n",
      "Epoch: 2\n",
      "Average Loss: 0.273\n",
      "Jaccard Index : 68.441\n",
      "Dice Coefficient : 77.880\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.779\n",
      "Epoch: 3\n",
      "Average Loss: 0.206\n",
      "Jaccard Index : 75.235\n",
      "Dice Coefficient : 83.873\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.839\n",
      "Epoch: 4\n",
      "Average Loss: 0.217\n",
      "Jaccard Index : 73.995\n",
      "Dice Coefficient : 82.903\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 5\n",
      "Average Loss: 0.211\n",
      "Jaccard Index : 76.083\n",
      "Dice Coefficient : 84.832\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.848\n",
      "Epoch: 6\n",
      "Average Loss: 0.293\n",
      "Jaccard Index : 62.817\n",
      "Dice Coefficient : 73.282\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 7\n",
      "Average Loss: 0.214\n",
      "Jaccard Index : 73.103\n",
      "Dice Coefficient : 81.771\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 8\n",
      "Average Loss: 0.183\n",
      "Jaccard Index : 77.032\n",
      "Dice Coefficient : 85.310\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.853\n",
      "Epoch: 9\n",
      "Average Loss: 0.204\n",
      "Jaccard Index : 74.491\n",
      "Dice Coefficient : 83.520\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 10\n",
      "Average Loss: 0.195\n",
      "Jaccard Index : 77.973\n",
      "Dice Coefficient : 86.018\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.860\n",
      "Epoch: 11\n",
      "Average Loss: 0.186\n",
      "Jaccard Index : 78.756\n",
      "Dice Coefficient : 86.428\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.864\n",
      "Epoch: 12\n",
      "Average Loss: 0.192\n",
      "Jaccard Index : 77.308\n",
      "Dice Coefficient : 85.681\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 13\n",
      "Average Loss: 0.195\n",
      "Jaccard Index : 77.685\n",
      "Dice Coefficient : 86.357\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 14\n",
      "Average Loss: 0.173\n",
      "Jaccard Index : 78.661\n",
      "Dice Coefficient : 86.713\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.867\n",
      "Epoch: 15\n",
      "Average Loss: 0.167\n",
      "Jaccard Index : 79.465\n",
      "Dice Coefficient : 87.271\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.873\n",
      "Epoch: 16\n",
      "Average Loss: 0.167\n",
      "Jaccard Index : 79.266\n",
      "Dice Coefficient : 87.173\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 17\n",
      "Average Loss: 0.179\n",
      "Jaccard Index : 78.988\n",
      "Dice Coefficient : 86.862\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 18\n",
      "Average Loss: 0.216\n",
      "Jaccard Index : 76.265\n",
      "Dice Coefficient : 84.982\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 19\n",
      "Average Loss: 0.180\n",
      "Jaccard Index : 79.108\n",
      "Dice Coefficient : 86.970\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 20\n",
      "Average Loss: 0.189\n",
      "Jaccard Index : 80.017\n",
      "Dice Coefficient : 87.508\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.875\n",
      "Epoch: 21\n",
      "Average Loss: 0.171\n",
      "Jaccard Index : 79.124\n",
      "Dice Coefficient : 87.024\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 22\n",
      "Average Loss: 0.158\n",
      "Jaccard Index : 80.241\n",
      "Dice Coefficient : 87.861\n",
      "==========================================\n",
      "==========================================\n",
      "Saving model at dice=0.879\n",
      "Epoch: 23\n",
      "Average Loss: 0.234\n",
      "Jaccard Index : 78.006\n",
      "Dice Coefficient : 85.844\n",
      "==========================================\n",
      "==========================================\n",
      "Epoch: 24\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "jacs = []\n",
    "dices = []\n",
    "\n",
    "score = 0\n",
    "best_score = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    train(model, epoch)\n",
    "    score = test(model)\n",
    "    \n",
    "    # Save best model\n",
    "    if score > best_score:\n",
    "        print(\"Saving model at dice={:.3f}\".format(score))\n",
    "        torch.save(model.state_dict(), '{}/{}.pth'.format(LOG_PATH, EXPERIMENT_NAME))\n",
    "        best_score = score\n",
    "\n",
    "        \n",
    "# Save losses\n",
    "losses = np.array(losses)\n",
    "np.savetxt(\"{}/{}_loss.txt\".format(LOG_PATH, EXPERIMENT_NAME), losses, delimiter=\",\")\n",
    "jacs = np.array(jacs)\n",
    "np.savetxt(\"{}/{}_jacs.txt\".format(LOG_PATH, EXPERIMENT_NAME), jacs, delimiter=\",\")\n",
    "dices = np.array(dices)\n",
    "np.savetxt(\"{}/{}_dices.txt\".format(LOG_PATH, EXPERIMENT_NAME), dices, delimiter=\",\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))\n",
    "print(\"--- Time taken to train : %s mins ---\" % ((end_time - start_time)//60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(jacs), max(dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "# b, g, r, y, o, -g, -m,\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(losses,linewidth=4)\n",
    "plt.title('{} loss'.format(\"Exp name\"))\n",
    "#plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss'], loc='upper left')\n",
    "plt.grid(True)\n",
    "# Plot training & validation iou_score values\n",
    "plt.subplot(122)\n",
    "plt.plot(jacs,linewidth=4)\n",
    "plt.plot(dices,linewidth=4)\n",
    "#plt.title('{} IOU score'.format(experiment_name))\n",
    "#plt.ylabel('iou_score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "plt.legend(['Jaccard', 'Dice'], loc='upper left')\n",
    "plt.savefig('{}/{}_graph.png'.format(LOG_PATH, EXPERIMENT_NAME), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
